{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook by [Prashant Brahmbhatt](https://www.github.com/hashbanger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facial landmarks are used to detect the features and different regions of a face namely:  \n",
    "- Eyes \n",
    "- Eyebrows\n",
    "- Nose\n",
    "- Mouth\n",
    "- Jawline  \n",
    "\n",
    "Detecting facial landmarks is a 'subset' of the **shape prediction problem**. A shape predictor localizes the key points of interests along with the shape. The motive is to detect import facial features using the shape prediction methods.  \n",
    "It involves two process:  \n",
    "- Loacalizing the face in the image  \n",
    "- Detecting the features in ROI (Region Of Interest)  \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localizing the Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the traditional Haar-Cascades to localize the face in the image. We can use a pretrained model for such purposes. The method isn't the aim but somehow we have to get a bounding box for the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting facial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several facial features detectors but most of them try to localize the following features:  \n",
    "- Left eye\n",
    "- Right eye\n",
    "- Left eyebrow\n",
    "- Right eyebrow\n",
    "- Nose\n",
    "- Jaw  \n",
    "  \n",
    "The *dlib* library has a facial features detector included is based on the research paper found [here](http://www.nada.kth.se/~sullivan/Papers/Kazemi_cvpr14.pdf).  \n",
    "\n",
    "The method involves:  \n",
    "- A training set of labeled facial landmarks on an image. These images are manually labeled, specifying specific (x, y)-coordinates of regions surrounding each facial structure.\n",
    "- Priors, of more specifically, the probability on distance between pairs of input pixels.  \n",
    "\n",
    "Given this training data, an ensemble of regression trees are trained to estimate the facial landmark positions directly from the pixel intensities themselves, there's no requirement of feature extraction.  \n",
    "The end result is a facial landmark detector that can be used to detect facial landmarks in real-time with high quality predictions.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dlib's facial detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a pretrained facial landmarks detector inside the dlib library which estimates the location of 68 coordinates that map to the facial structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](img01.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These annotations are part of the 68 point iBUG 300-W dataset which the dlib facial landmark predictor was trained on.\n",
    "Other than this there are several other models that exist as the one trained on the known HELEN dataset.    \n",
    "\n",
    "Dlib framework can used to train for own custom shape detetcion purposes as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting facial landmarks using Dlib ad OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create file *facial_landmarks.py* and write the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# contructing the argument parser for parsing the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", '--shape-predictor', required = True,\n",
    "               help = 'path to facial landmark predictor')\n",
    "ap.add_argument(\"-i\", '--image', required = True,\n",
    "               help = 'path to input image')\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the imutil's face_util to access our helper functions above.  \n",
    "We will then import dlib.   \n",
    "\n",
    "Parsing the arguments.   \n",
    "- --shape-predictor : This is the path to dlibâ€™s pre-trained facial landmark detector. You can download the detector model here\n",
    "\n",
    "- --image : The path to the input image that we want to detect facial landmarks on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the dlib detector and facial landmark predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(args[\"shape_predictor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we load the facial landmark predictor using the path to the supplied *--shape-predictor*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we detect the facial landmark in our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(args['image'])\n",
    "image = imutils.resize(image ,width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#detecting the faces in grayscale image\n",
    "rects = detector(gray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our input image from disk, then pre-processes the image by resizing to have a width of 500 pixels and converting it to grayscale.  \n",
    "\n",
    "Then detecting the bounding box of faces in our image.  \n",
    "The first parameter for our detector is our gray image and the second is the number of [image pyramid](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_pyramids/py_pyramids.html) layers to apply when upscaling before we apply the detector (same as computing cv2.pyrUp N number of times). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the (x, y) coordinates of the faces in the image, we can now apply facial landmark detection to each of the face regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, rect) in enumerate(rects):\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "    # converting the dlib's rectangle to our traditional bounding box\n",
    "    (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    #show the face number\n",
    "    cv2.putText(image, \"Face #{}\".format(i +1), (x - 10, y - 10),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    for (x, y) in shape:\n",
    "        cv2.circle(image, (x,y), 1, (0, 0, 255), -1)\n",
    "        \n",
    "    cv2.imshow(\"Output\", image)\n",
    "    cv2.waitKey(0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to run the program we run the script as:  \n",
    "\n",
    "    *python facial_landmarks.py --shape-predictor shape_predictor_68_face_landmarks.dat --image images/image1.jpg*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**  \n",
    "[www.medium.com ]()  \n",
    "[www.pyimagesearch.com]()    \n",
    "[www.stackoverflow.com]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
