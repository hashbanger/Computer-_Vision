{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drowsiness Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Prashant Brahmbhatt](https://www/github.com/hashbanger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following code is sugested to be written combinely in a python script as it requires command line arguments*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The procedure\n",
    "The process is fairly straightforward:    \n",
    "- The camera will detect the face.  \n",
    "- Then we will extract the eye region from the facial landmark detection\n",
    "- We will compute the eye aspect ratio to determine if the eyes are closed.\n",
    "- If eyes remain closed for sufficiently long time will trigger an alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import playsound\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mac OS one would also require `pip install pyobj`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a function to play a sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_alarm(path):\n",
    "    '''Takes in the path of the sound to play, mp3/WAV'''\n",
    "    playsound.playsound(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our EAR calculation function more on that [here](https://github.com/hashbanger/Computer_Vision/blob/master/DrowsinessDetection/Eye_Blinking_Detection/py_cv_eyeBlinking.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    '''Taking the array of eye coordinates and returning the ratio'''\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    \n",
    "    ear = (A + B)/ (2 * C)\n",
    "    \n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in our drowsiness detection unlike the blinking case the eyes will not open but rather will remain closed. So the EAR value dropped will not increase again indicating the person has closed their eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
    "    help=\"path to facial landmark predictor\")\n",
    "ap.add_argument(\"-a\", \"--alarm\", type=str, default=\"\",\n",
    "    help=\"path alarm .WAV file\")\n",
    "ap.add_argument(\"-w\", \"--webcam\", type=int, default=0,\n",
    "    help=\"index of webcam on system\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `--shape-predictor` : The path for our pretrained facial landmark detector.\n",
    "- `--alarm` : An optional argument to define the sound file to be played as alarm.\n",
    "- `--webcam` : The default value is 0 as for in-built webcam, for external pass on 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to set up two constants that one may require tuning as per their requirements. We also require two variables declaration.\n",
    "\n",
    "- The first constant is for setting the default threshold value.\n",
    "- The second constant is the number of frames the EAR should be below threshold to set off the alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EYE_AR_THRESH = 0.3\n",
    "EYE_AR_CONSEC_FRAMES = 48  # decreasing it will cause the detector to be more sensitive\n",
    " \n",
    "# initialize the frame counter as well as a boolean used to\n",
    "# indicate if the alarm is going off\n",
    "\n",
    "COUNTER = 0\n",
    "ALARM_ON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the dlib's face detector(the pretrained model) to get the face in the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading up the facial landmark detector\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(args[\"shape_predictor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the eye blink detection we get our eye indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"setting up Video Stream...\")\n",
    "vs = VideoStream(src=args[\"webcam\"]).start()\n",
    "time.sleep(1.0)\n",
    " \n",
    "# loop over frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    for rect in rects:\n",
    "        # determining the facial landmarks and then coverting them to a numpy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # extract the left and right eye coordinates, then use the\n",
    "        # coordinates to compute the eye aspect ratio for both eyes\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "        # averaging the eye aspect ratio together for both eyes\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "    \n",
    "        # compute the convex hull for the left and right eye, then\n",
    "        # visualize each of the eyes\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "\n",
    "            # if the eyes were close for sufficient time then sound the alarm\n",
    "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                # if teh alarm is not turn it on\n",
    "                if not ALARM_ON:\n",
    "                    ALARM_ON = True\n",
    "\n",
    "                # checking if the alarm file is supplied \n",
    "                # if present then we will play in the background using the Thread\n",
    "                    if args['alarm'] != '':\n",
    "                        t = Thread(target=sound_alarm, args= (args['alarm'],))\n",
    "                        t.deamon = True\n",
    "                        t.start()\n",
    "\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        else:\n",
    "            COUNTER = 0\n",
    "            ALARM_ON = False\n",
    "        \n",
    "        # draw the computed eye aspect ratio on the frame to help\n",
    "        # with debugging and setting the correct eye aspect ratio\n",
    "        # thresholds and frame counters\n",
    "        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    " \n",
    "    # show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "#do a clean up\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
