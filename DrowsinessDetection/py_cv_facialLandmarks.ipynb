{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook by [Prashant Brahmbhatt](https://www.github.com/hashbanger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The facial landmarks are used to detect the features and different regions of a face namely:  \n",
    "- Eyes \n",
    "- Eyebrows\n",
    "- Nose\n",
    "- Mouth\n",
    "- Jawline  \n",
    "\n",
    "Detecting facial landmarks is a 'subset' of the **shape prediction problem**. A shape predictor localizes the key points of interests along with the shape. The motive is to detect import facial features using the shape prediction methods.  \n",
    "It involves two process:  \n",
    "- Loacalizing the face in the image  \n",
    "- Detecting the features in ROI (Region Of Interest)  \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localizing the Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the traditional Haar-Cascades to localize the face in the image. We can use a pretrained model for such purposes. The method isn't the aim but somehow we have to get a bounding box for the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting facial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several facial features detectors but most of them try to localize the following features:  \n",
    "- Left eye\n",
    "- Right eye\n",
    "- Left eyebrow\n",
    "- Right eyebrow\n",
    "- Nose\n",
    "- Jaw  \n",
    "  \n",
    "The *dlib* library has a facial features detector included is based on the research paper found [here](http://www.nada.kth.se/~sullivan/Papers/Kazemi_cvpr14.pdf).  \n",
    "\n",
    "The method involves:  \n",
    "- A training set of labeled facial landmarks on an image. These images are manually labeled, specifying specific (x, y)-coordinates of regions surrounding each facial structure.\n",
    "- Priors, of more specifically, the probability on distance between pairs of input pixels.  \n",
    "\n",
    "Given this training data, an ensemble of regression trees are trained to estimate the facial landmark positions directly from the pixel intensities themselves, there's no requirement of feature extraction.  \n",
    "The end result is a facial landmark detector that can be used to detect facial landmarks in real-time with high quality predictions.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dlib's facial detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a pretrained facial landmarks detector inside the dlib library which estimates the location of 68 coordinates that map to the facial structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](img01.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These annotations are part of the 68 point iBUG 300-W dataset which the dlib facial landmark predictor was trained on.\n",
    "Other than this there are several other models that exist as the one trained on the known HELEN dataset.    \n",
    "\n",
    "Dlib framework can used to train for own custom shape detetcion purposes as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting facial landmarks using Dlib ad OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to add some few convenient functions to our im utils library, inside face_utils.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import playsound\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First function is a *rect_to_bb* for \"rectangle to bounding box\". We normally think of bounding box as in the format (x, y, w, h) for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "    \"takes a bounding box produced by the dlib detector\"\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() -y\n",
    "    \n",
    "    #returning the tuple of (x,y,w,h)\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function is the *shape_to_np* function which we will use to convert the 68 (x,y) coordinates returned by the dlib detector into a numpy array so our work would get easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype = 'int'):\n",
    "    # initializing the list of (x, y) coordinates\n",
    "    coords = np.zeros((68,2), dtype=dtype)\n",
    "    \n",
    "    #looping over the 68 remarks and convert them to a tuple\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "        \n",
    "    #returning the list of x,y coordinates\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**  \n",
    "[www.medium.com ]()  \n",
    "[www.pyimagesearch.com]()    \n",
    "[www.stackoverflow.com]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
